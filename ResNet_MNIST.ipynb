{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0J8M+6RM9DITBkI/8ckM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch0uchou/Resnet50-MNIST/blob/main/ResNet_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Resnet50"
      ],
      "metadata": {
        "id": "aWwV-DzjtM_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten, ZeroPadding2D, MaxPooling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Load MNIST data\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "# Expand the dimensions of the data to (28, 28, 1) to fit the ConvNet\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "# Define the identity block\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
        "               name='res' + str(stage) + block + '_branch2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
        "               name='res' + str(stage) + block + '_branch2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
        "               name='res' + str(stage) + block + '_branch2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2c')(X)\n",
        "    # Add shortcut value to main path\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    return X\n",
        "# Define the convolutional block\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), padding='valid',\n",
        "               name='res' + str(stage) + block + '_branch2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides=(1, 1), padding='same',\n",
        "               name='res' + str(stage) + block + '_branch2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides=(1, 1), padding='valid',\n",
        "               name='res' + str(stage) + block + '_branch2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch2c')(X)\n",
        "    # Shortcut Path\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), padding='valid',\n",
        "                        name='res' + str(stage) + block + '_branch1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name='bn' + str(stage) + block + '_branch1')(X_shortcut)\n",
        "    # Add shortcut value to main path\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    return X\n",
        "# Define the ResNet50 model adjusted for the MNIST dataset\n",
        "def ResNet50(input_shape=(28, 28, 1), classes=10):\n",
        "    # Define the input tensor\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(1, 1), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(1, 1))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "    return model\n",
        "# Instantiate the model\n",
        "model = ResNet50(input_shape=(28, 28, 1), classes=10)\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Fit the model on the data\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
        "# Save the model\n",
        "model.save('mnist_resnet50.h5')\n",
        "# Output to indicate save completion\n",
        "print(\"Model saved as mnist_resnet50.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BynKicD2tPmP",
        "outputId": "1edc5ebe-ef5e-4963-bdee-73c08d44430c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 241s 107ms/step - loss: 0.1837 - accuracy: 0.9518 - val_loss: 0.1388 - val_accuracy: 0.9583\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 200s 107ms/step - loss: 0.0771 - accuracy: 0.9781 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 198s 106ms/step - loss: 0.0548 - accuracy: 0.9836 - val_loss: 0.0923 - val_accuracy: 0.9751\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 200s 107ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.0625 - val_accuracy: 0.9807\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 200s 107ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.0717 - val_accuracy: 0.9802\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 200s 107ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 199s 106ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0588 - val_accuracy: 0.9796\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 200s 107ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.0389 - val_accuracy: 0.9873\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 198s 106ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0292 - val_accuracy: 0.9917\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 198s 106ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0257 - val_accuracy: 0.9924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mnist_resnet50.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from PIL import Image\n",
        "# Load the model\n",
        "model = load_model('mnist_resnet50.h5')\n",
        "# Load the image\n",
        "image_path = 'image.png'\n",
        "image = load_img(image_path, color_mode='grayscale' if model.input_shape[-1] == 1 else 'rgb', target_size=(28, 28))\n",
        "image = img_to_array(image)\n",
        "image = image.astype('float32')\n",
        "image /= 255.0\n",
        "# MNIST images are usually grayscale; check your model's expected input shape\n",
        "if model.input_shape[-1] == 1 and image.shape[-1] == 3:\n",
        "    image = image.mean(axis=-1, keepdims=True)\n",
        "# Add batch dimension (model expects (batch_size, height, width, channels))\n",
        "image = np.expand_dims(image, axis=0)\n",
        "# Predict\n",
        "prediction = model.predict(image)\n",
        "# Output prediction\n",
        "predicted_class = np.argmax(prediction, axis=1)\n",
        "print(f'Predicted class: {predicted_class[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rfpgmia87Z1",
        "outputId": "549e3049-2de9-43de-928a-3b96d1e781e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted class: 4\n"
          ]
        }
      ]
    }
  ]
}